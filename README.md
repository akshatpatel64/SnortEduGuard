About the Project: SnortEduGuard – Student Integrity Surveillance System
As a Teaching Assistant at the University of Maryland, I often oversee lab sessions, in-class quizzes, and exams. Over time, I noticed a recurring issue—students frequently attempt to bypass academic integrity policies by using generative AI tools, cheating platforms, or VPNs to evade detection. While institutions rely on browser lockdown software like LockDown Browser or proctoring tools, these are not foolproof. As someone passionate about cybersecurity, I wanted to design a system that works at the network level, giving instructors real-time visibility into potentially unauthorized activity.

That motivation led to the creation of SnortEduGuard, a production-ready academic intrusion detection system (IDS) that detects, logs, filters, and summarizes network traffic during exams or classroom sessions. The goal was to build a system that’s not only technically sound, but also useful in real-world academic settings.

The project is powered by Snort 3, a modern packet inspection engine. I wrote custom rules to detect specific categories of traffic that may indicate academic dishonesty or misuse of resources. These included generative AI tools (such as ChatGPT, Bard, Claude, and Perplexity), study-help sites (Chegg, CourseHero, Quizlet), VPNs (NordVPN, ProtonVPN), collaboration platforms (Discord, Slack, WhatsApp), and even C2 patterns and port scans like Nmap. For safe and allowed domains like umd.edu, canvas.instructure.com, and zoom.us, I added whitelist rules to separate authorized traffic.

Snort writes all detected alerts to a log file called alert.fast. I developed a custom Python script (parse_alerts.py) that uses regular expressions to extract useful information from each alert—such as timestamp, source and destination IPs, protocol, SID, and priority—and then writes that data to a structured JSON file (parsed_alerts.json). This JSON file serves as the data source for the real-time dashboard.

The dashboard itself was built using Flask, Chart.js, and Bootstrap 5. It auto-refreshes every 10 seconds, color-codes alerts by priority, and allows instructors to search, filter, export to CSV or PDF, and visualize alert distribution. I also implemented login functionality and created a modern landing page with University of Maryland and Bitcamp 2025 branding.

To elevate the project even further, I added a Smart Search AI Assistant. This feature allows instructors to enter natural language queries like "Show Chegg activity in the last 30 minutes" or "AI access logs today." Behind the scenes, the query is parsed using the spaCy NLP library in parse_query.py, mapped to categories and timestamps, and then passed to smart_filter.py, which filters relevant logs from the alert file. Summaries are then generated using a lightweight summarization engine (summarizer.py) that outputs clean, readable interpretations of what happened—for example, “192.168.1.105 attempted to access ChatGPT at 10:42 AM.”

One of the most difficult challenges I faced was configuring Snort 3 logging on macOS, particularly working with Lua configs and redirecting output without losing data. Ensuring the parser could safely read logs in real time, without blocking or corrupting the alert.fast file, required careful design. The AI integration also involved significant effort to ensure natural queries would reliably match the right traffic.

Through this project, I gained deep hands-on experience with packet inspection, Snort rule design, real-time log processing, and integrating AI into cybersecurity tooling. I also learned how to present technical data in a visual and usable format for end users, which is critical in applied security contexts.

SnortEduGuard is more than a demo—it’s a system that could be deployed in a real classroom, lab, or exam setting. It encourages academic integrity not through surveillance, but by promoting awareness and visibility. It shows how cybersecurity techniques like rule-based detection, log analysis, and AI-enhanced summarization can be adapted for educational environments to make them more secure, transparent, and fair.


